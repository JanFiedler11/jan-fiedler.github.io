(function(e){function t(t){for(var a,s,r=t[0],l=t[1],c=t[2],h=0,u=[];h<r.length;h++)s=r[h],Object.prototype.hasOwnProperty.call(n,s)&&n[s]&&u.push(n[s][0]),n[s]=0;for(a in l)Object.prototype.hasOwnProperty.call(l,a)&&(e[a]=l[a]);d&&d(t);while(u.length)u.shift()();return o.push.apply(o,c||[]),i()}function i(){for(var e,t=0;t<o.length;t++){for(var i=o[t],a=!0,r=1;r<i.length;r++){var l=i[r];0!==n[l]&&(a=!1)}a&&(o.splice(t--,1),e=s(s.s=i[0]))}return e}var a={},n={app:0},o=[];function s(t){if(a[t])return a[t].exports;var i=a[t]={i:t,l:!1,exports:{}};return e[t].call(i.exports,i,i.exports,s),i.l=!0,i.exports}s.m=e,s.c=a,s.d=function(e,t,i){s.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:i})},s.r=function(e){"undefined"!==typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},s.t=function(e,t){if(1&t&&(e=s(e)),8&t)return e;if(4&t&&"object"===typeof e&&e&&e.__esModule)return e;var i=Object.create(null);if(s.r(i),Object.defineProperty(i,"default",{enumerable:!0,value:e}),2&t&&"string"!=typeof e)for(var a in e)s.d(i,a,function(t){return e[t]}.bind(null,a));return i},s.n=function(e){var t=e&&e.__esModule?function(){return e["default"]}:function(){return e};return s.d(t,"a",t),t},s.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},s.p="/jan-fiedler.github.io/";var r=window["webpackJsonp"]=window["webpackJsonp"]||[],l=r.push.bind(r);r.push=t,r=r.slice();for(var c=0;c<r.length;c++)t(r[c]);var d=l;o.push([0,"chunk-vendors"]),i()})({0:function(e,t,i){e.exports=i("56d7")},"034f":function(e,t,i){"use strict";i("85ec")},"0942":function(e,t,i){"use strict";i("fbe2")},"0af9":function(e,t,i){e.exports=i.p+"img/harry.eb8f96b7.jpeg"},"0b62":function(e,t,i){},1009:function(e,t){},"13c2":function(e,t,i){"use strict";i("4ebe")},1512:function(e,t,i){"use strict";i("94e4")},"1d61":function(e,t,i){"use strict";var a=i("c2ec"),n=i("d1e6"),o=(i("40c6"),i("2877")),s=Object(o["a"])(n["default"],a["a"],a["b"],!1,null,"3787cedf",null);t["default"]=s.exports},"265a":function(e,t,i){e.exports=i.p+"img/result.bcbb45dc.png"},2712:function(e,t,i){},"2e4c":function(e,t,i){e.exports=i.p+"img/impulse.87012eba.png"},"2efa":function(e,t,i){"use strict";i("cd9e")},"3c5f":function(e,t,i){},"3f0c":function(e,t,i){},"40c6":function(e,t,i){"use strict";i("2712")},"412b":function(e,t,i){},"44da":function(e,t,i){e.exports=i.p+"img/about-picture.b56523f7.jpg"},"48fa":function(e,t,i){},"4d40":function(e,t,i){},"4d41":function(e,t,i){"use strict";i("6ac6")},"4ebe":function(e,t,i){},"4f9b":function(e,t,i){},5040:function(e,t,i){e.exports=i.p+"img/data.3999ad17.png"},"53e5":function(e,t,i){e.exports=i.p+"img/lumos.aeff513c.gif"},"56d7":function(e,t,i){"use strict";i.r(t);i("4160"),i("159b"),i("e260"),i("e6cf"),i("cca6"),i("a79d");var a=i("2b0e"),n=i("8c4f"),o=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"home"},[i("div",{staticClass:"my_header"},[i("DesktopHeader",{attrs:{id:"DesktopHeader"}}),i("MobileHeader",{attrs:{id:"MobileHeader"}})],1),i("div",{staticClass:"my_body"},[i("div",{attrs:{id:"desktop-body"}},[i("div",{on:{click:function(t){return e.go_to("Nlp")}}},[i("DesktopArticleCard",{attrs:{topic:"NLP",title:"Identifying Antisemitic Tweets with Natural Language Processing in Python",preview_text:"Let me show you a basic approach to classify text with machine learning, which won a competition at the Indiana University. This post is for everybody, who would like to get started with natural language processing (NLP) in Python.",author_date:"Jan Fiedler ♥ Aug 18, 2020",picture:e.antisem,id:"article_nlp_desktop"}})],1),i("div",{on:{click:function(t){return e.go_to("TinyML")}}},[i("DesktopArticleCard",{attrs:{topic:"TinyML",title:"Audio Recognition with Embedded Machine Learning",preview_text:"How do Harry Potter and embedded machine learning match each other? Lets have a look, how easy it is to run machine learning models on low-power microcontrollers.",author_date:"Jan Fiedler ♥ Aug 02, 2020",picture:e.harry,id:"article_ml_desktop"}})],1)]),i("div",{attrs:{id:"mobile-body"}},[i("div",{on:{click:function(t){return e.go_to("Nlp")}}},[i("MobileArticleCard",{attrs:{topic:"NLP",title:"Identifying Antisemitic Tweets with Natural Language Processing in Python",preview_text:"Let me show you a basic approach to classify text with machine learning, which won a competition at the Indiana University. This post is for everybody, who would like to get started with natural language processing (NLP) in Python.",author_date:"Jan Fiedler ♥ Aug 18, 2020",picture:e.antisem,id:"article_nlp"}})],1),i("div",{on:{click:function(t){return e.go_to("TinyML")}}},[i("MobileArticleCard",{attrs:{topic:"TinyML",title:"Audio Recognition with Embedded Machine Learning",preview_text:"How do Harry Potter and embedded machine learning match each other? Lets have a look, how easy it is to run machine learning models on low-power microcontrollers.",author_date:"Jan Fiedler ♥ Aug 02, 2020",picture:e.harry,id:"article_ml"}})],1)])])])},s=[],r=function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("div",{staticClass:"header"},[a("Drawer",{attrs:{align:"left",closeable:!0},on:{close:e.toggle}},[e.open?a("div",{staticClass:"about-card"},[a("div",{staticClass:"about-entry"},[a("p",{attrs:{id:"about-me"}},[e._v(" About me")]),a("h3",{attrs:{id:"myname"}},[e._v("Jan Fiedler")]),a("img",{attrs:{id:"picture",src:i("44da"),width:"400px",height:"400px"}})]),a("div",{staticClass:"about-text"},[a("p",[e._v(" I am a student from Berlin with an affinity for computer technology and a bachelor's degree in electrical engineering. In 2021, I will finish my master's study in Computer Engineering. The process of developing hard- and software has been and still is an extremely fulfilling joy for me. I am pretty much interested in the whole stack, from embedded to web, and everything in between. This is why I tend to do some side projects from time to time, which I want to share with everybody. Thanks for coming by :) ")])])]):e._e()]),a("div",{staticClass:"webname"},[a("h1",[e._v("Jan Fiedler")]),a("h3",[e._v("IoT Enthusiast, Maker and Computer Engineer")]),a("div",{staticClass:"icon-list"},[a("b-button",{staticClass:"mb-2",attrs:{variant:"transparent"},on:{click:function(t){return e.toggle()}}},[a("b-icon",{staticClass:"icons",attrs:{icon:"person-fill",id:"person"}})],1),a("b-button",{staticClass:"mb-2",attrs:{variant:"transparent",onclick:"javascript: window.location.href='mailto:jan.fiedler.b@gmail.com';"}},[a("b-icon",{staticClass:"icons",attrs:{icon:"envelope-fill",id:"mail"}})],1),a("b-button",{staticClass:"mb-2",attrs:{variant:"transparent",onclick:"window.open('https://www.linkedin.com/in/jan-fiedler-285856186')"}},[a("b-icon",{staticClass:"icons",attrs:{icon:"linkedin",id:"linkedin"}})],1)],1)])],1)},l=[],c=i("0289"),d=i.n(c),h={name:"header",data:function(){return{open:!1}},components:{Drawer:d.a},methods:{toggle:function(){this.open=!this.open}}},u=h,p=(i("fd6d"),i("2877")),m=Object(p["a"])(u,r,l,!1,null,null,null),f=m.exports,g=function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("div",{staticClass:"header"},[a("Drawer",{attrs:{align:"left",closeable:!0},on:{close:e.toggle}},[e.open?a("div",{staticClass:"about-card"},[a("div",{staticClass:"about-entry"},[a("p",{attrs:{id:"about-me"}},[e._v(" About me")]),a("h3",{attrs:{id:"myname"}},[e._v("Jan Fiedler")]),a("img",{attrs:{id:"picture",src:i("44da"),width:"400px",height:"400px"}})]),a("div",{staticClass:"about-text"},[a("p",[e._v(" I am a student from Berlin with an affinity for computer technology and a bachelor's degree in electrical engineering. In 2021, I will finish my master's study in Computer Engineering. The process of developing hard- and software has been and still is an extremely fulfilling joy for me. I am pretty much interested in the whole stack, from embedded to web, and everything in between. This is why I tend to do some side projects from time to time, which I want to share with everybody. Thanks for coming by :) ")])])]):e._e()]),a("div",{staticClass:"webname"},[a("h1",{attrs:{id:"website-name"},on:{click:function(t){return e.$router.push("/")}}},[e._v("Jan-Fiedler")]),a("h3",[e._v("IoT Enthusiast, Maker and Computer Engineer")]),a("div",{staticClass:"icon-list"},[a("b-button",{staticClass:"mb-2",attrs:{variant:"transparent"},on:{click:function(t){return e.toggle()}}},[a("b-icon",{staticClass:"icons",attrs:{icon:"person-fill",id:"person"}})],1),a("b-button",{staticClass:"mb-2",attrs:{variant:"transparent",onclick:"javascript: window.location.href='mailto:jan.fiedler.b@gmail.com';"}},[a("b-icon",{staticClass:"icons",attrs:{icon:"envelope-fill",id:"mail"}})],1),a("b-button",{staticClass:"mb-2",attrs:{size:"lg",variant:"transparent",onclick:"window.open('https://www.linkedin.com/in/jan-fiedler-285856186')"}},[a("b-icon",{staticClass:"icons",attrs:{icon:"linkedin",id:"linkedin"}})],1)],1)])],1)},w=[],b={name:"header",data:function(){return{open:!1}},components:{Drawer:d.a},methods:{toggle:function(){this.open=!this.open}}},y=b,x=(i("822e"),Object(p["a"])(y,g,w,!1,null,"2a201b0e",null)),v=x.exports,k=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"card"},[i("img",{attrs:{src:e.picture,id:"picture",width:"348px",height:"auto"}}),i("div",{staticClass:"below"},[i("h4",{attrs:{id:"topic"}},[e._v(e._s(e.topic))]),i("h5",{attrs:{id:"author_date"}},[e._v(" "+e._s(e.author_date))])]),i("h3",{attrs:{id:"article-title"}},[e._v(" "+e._s(e.title)+" ")]),i("div",{staticClass:"preview"},[i("p",[e._v(" "+e._s(e.preview_text)+" ")])])])},T=[],_={props:{topic:{type:String,default:"New Title"},picture:{type:String,default:i("0af9")},author_date:{type:String,default:"Jan Fiedler ♥ some date"},title:{type:String,default:"Title of the article"},preview_text:{type:String,default:"Text Text Text Text Text Text Text Text Text Text Text Text Text Text Text Text Text Text Text Text Text Text Text Text "}}},I=_,C=(i("b261"),Object(p["a"])(I,k,T,!1,null,"f3e7bd62",null)),M=C.exports,D=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"card"},[i("img",{attrs:{src:e.picture,id:"picture",width:"100%",height:"auto"}}),i("div",{staticClass:"below"},[i("h4",{attrs:{id:"topic"}},[e._v(e._s(e.topic))]),i("h5",{attrs:{id:"author_date"}},[e._v(" "+e._s(e.author_date))])]),i("h3",{attrs:{id:"article-title"}},[e._v(" "+e._s(e.title)+" ")]),i("div",{staticClass:"preview"},[i("p",[e._v(" "+e._s(e.preview_text)+" ")])])])},j=[],z={props:{topic:{type:String,default:"New Title"},picture:{type:String,default:i("0af9")},author_date:{type:String,default:"Jan Fiedler ♥ some date"},title:{type:String,default:"Title of the article"},preview_text:{type:String,default:"Text Text Text Text Text Text Text Text Text Text Text Text Text Text Text Text Text Text Text Text Text Text Text Text "}}},A=z,S=(i("953c"),Object(p["a"])(A,D,j,!1,null,"153656f2",null)),L=S.exports,P={name:"Home",components:{DesktopHeader:f,MobileHeader:v,DesktopArticleCard:M,MobileArticleCard:L},data:function(){return{harry:i("0af9"),antisem:i("c434")}},methods:{go_to:function(e){this.$router.push({name:e})}}},E=P,N=(i("cccb"),Object(p["a"])(E,o,s,!1,null,null,null)),F=N.exports,O=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"home"},[i("div",{staticClass:"my_header"},[i("DesktopHeader",{attrs:{id:"DesktopHeader"}}),i("MobileHeader",{attrs:{id:"MobileHeader"}})],1),i("div",{attrs:{id:"desktop-body"}},[i("DesktopEntry",{attrs:{title:"Identifying Antisemitic Tweets with Natural Language Processing in Python",subtitle:"Let me show you a basic approach to classify text with machine learning, which won a competition at the Indiana University. This post is for everybody, who would like to get started with natural language processing (NLP) in Python.",author_date:"Jan Fiedler ♥ Aug 18, 2020",picture:e.certificate}}),i("Desktop-Text",{attrs:{text:"Some weeks a good friend of mine, with a background in humanities and antisemitic studies, asked me if I would like to take part in an event at the Indiana University. The event was divided into a Datathon and Hackathon, a virtual workshop and competition with the goal to recognize antisemitism online and use programming to take care of this task automatically."}}),i("Desktop-Text",{attrs:{text:"You can read about the event in detail",linktext:"HERE!",link:"https://news.iu.edu/stories/2020/07/iub/24-antisemitism-workshop-twitter-competition-hackathon-datathon.html#"}}),i("Desktop-Text",{attrs:{text:"The use of social media in our modern society is huge and getting bigger by the day. With the increasing number of users, there is also a portion of people growing, who use these platforms as an outlet for homophobia, sexism, racism as well as antisemitism. Those hate speeches evolved from little internet trolls to a real pain to the digital society we are living in. The event aimed to fight against this particular threat and I was more than happy to contribute!"}}),i("Desktop-Text",{attrs:{text:"The Datathon was about manually annotating random tweets with keywords like „Jews“ or „Israel“ in it. For this task, a well-founded background in antisemitic studies was needed. The goal of the Hackathon, on the other hand, was to classify tweets programmatically as either antisemitic (1) or non-antisemitic (0). For the hackathon, a bunch of labeled data was given in a file. Because I was the only one with programming skills in the team, I was happy to think about a solution for the hackathon, even though I had no experience with NLP at all"}}),i("Desktop-Text",{attrs:{text:"4 weeks later",size:"18px",weight:"550",align:"left"}}),e._m(0),i("Desktop-Text",{attrs:{text:'"The first prize of $500 went to Jan Fiedler, Sydney Grad, Sophie Mariassy and Victor Tschiskale, students from Canada and Germany."',size:"25px",weight:"100",align:"center"}}),e._m(1),i("Desktop-Text",{attrs:{text:"We actually won!"}}),i("Desktop-Text",{attrs:{text:"The rest of my team annotated a crazy amount of tweets properly, which won us the datathon. For the hackathon, we also took first place because of my machine learning model, which achieved an F1 score of 0.90 on the final validation data."}}),i("Desktop-Text",{attrs:{text:"A basic NLP approach",size:"20px",weight:"550",align:"left"}}),i("Desktop-Text",{attrs:{text:"In the following article, I want to reveal you a really basic approach for classifying text in Python. This approach is based on an article from Rebecca Vickery on",linktext:"medium.",link:"https://medium.com/vickdata/detecting-hate-speech-in-tweets-natural-language-processing-in-python-for-beginners-4e591952223"}}),i("Desktop-Text",{attrs:{text:"Thank you so much for sharing!"}}),i("Desktop-Text",{attrs:{text:"The Data",size:"18px",weight:"550",align:"left"}}),i("Desktop-Text",{attrs:{text:"As I said, there was a data set given in a JSON file, consisting of labeled tweets either as antisemitic (1) or non-antisemitic (0). I converted the given JSON into a pandas data frame to keep the data science manner 🙂"}}),i("DesktopTable",{attrs:{items:e.table0,caption:"a part of the given data set"}}),i("Desktop-Text",{attrs:{text:"Cleaning the Data",size:"18px",weight:"550",align:"left"}}),i("Desktop-Text",{attrs:{text:"In order to make any machine algorithm work well, I had to pre-process the given text data. As you can see, tweets contain characters like hashtags or emojis, which won’t be meaningful to a machine learning algorithm."}}),i("Desktop-Text",{attrs:{text:"I am using the re library in Python for removing these characters."}}),i("Desktop-Code",{attrs:{content:' import re\n\n      def f_clean_data(df,field):\n          df[field]=df[field].str.lower()\n          df[field] = df[field].apply(lambda elem: \n          re.sub(r"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?","", elem))\n          return df'}}),i("Desktop-Text",{attrs:{text:"This function also converts every word in lower case, which is nice because the following algorithm will count the frequency of words. Without this processing, a lower and upper version of the same word would count differently, even if the meaning is the same.\nLet’s have a look at the cleaned data."}}),i("DesktopTable",{attrs:{items:e.table1,caption:"a part of the given data set - cleaned"}}),i("Desktop-Text",{attrs:{text:"This is looking a lot cleaner. After some research, I thought another important step of cleaning my tweets is needed: removing stop words and lemmatization. Stop words are the most common and basic words in a language like „to“, „the“ or „and“. Those words had to be removed because they can’t give a hint about the intention of a tweet. Lemmatization is a linguistic process of affiliating a word to its very basic form (lemma). For example „runs“, „ran“ and „running“ are forms of the same lemma: „run“. Like in the lowercase processing, this is really important to identify equal words even if they are in different forms."}}),i("Desktop-Text",{attrs:{text:"I implemented this by using spacy, a really strong library for NLP. I am basically splitting up my tweet as a text in separate words (tokens). If the token is a stop word, I don’t want to append it to my cleaned text. If it is not a stop word, I want to apply the lemmatization and append it to my cleaned text."}}),i("Desktop-Code",{attrs:{content:' import spacy\n\n      nlp=spacy.load("en_core_web_sm")\n\n      def remove_stop_apply_lemma_for_string(text):\n          cleaned_text=""\n          tokens=nlp(text)\n          for token in tokens:\n              if not token.is_stop:\n                  cleaned_text=cleaned_text+" "+token.lemma_\n    \n          return cleaned_text'}}),i("Desktop-Text",{attrs:{text:"At this point in pre-processing the tweets, it is getting harder to understand the text as a human being. On the other hand, this will improve the performance of our algorithm in the end."}}),i("DesktopTable",{attrs:{items:e.table2,caption:"a part of the given data set – applied lemmatization and removed stop words"}}),i("Desktop-Text",{attrs:{text:"Balancing the Classes",size:"18px",weight:"550",align:"left"}}),i("Desktop-Text",{attrs:{text:"After having the data cleaned I realized, that the number of non-antisemitic tweets predominated the antisemitic tweets. If the machine learning model is only being fed with tweets, which are labeled as 0, it is more likely, that it will predict new tweets to 0 in the end.\nHaving the classes balanced is an important requirement to proceed in this stage."}}),i("Desktop-Text",{attrs:{text:"It is one approach, to either upsample or downsample the minority/majority of a class. At this point, it was really about trying which method scores better results. I went for upsampling the minority, where samples of the minority are being used multiple times until the class is the same size as the majority. For this implementation, I used the functions of the sklearn library."}}),i("Desktop-Code",{attrs:{content:' from sklearn.utils import resample\n      import pandas as pd\n\n      #they are like 1200 more antisemitic tweets than not antisemitic.\n      #Thats why we are upsampling the minority.\n      train_majority=clean_data[clean_data.Label=="0"]\n      train_minority=clean_data[clean_data.Label=="1"]\n    \n      train_minority_upsampled=resample(train_minority,replace=True,\n      n_samples=len(train_majority),random_state=123)\n\n      train_upsampled=pd.concat([train_minority_upsampled,train_majority])'}}),i("Desktop-Text",{attrs:{text:"The Algorithm",size:"18px",weight:"550",align:"left"}}),i("Desktop-Text",{attrs:{text:"After having our whole data-set prepared, let’s have a look at the chosen algorithm. A common approach to detect patterns in text is the use of the Bag of Words (BoW) model. A BoW model counts the frequency of single words and assigns a weight proportional to this frequency. I built this model with the help of the functions of the sklearn library."}}),i("Desktop-Text",{attrs:{text:"CountVectoriser",size:"15px",weight:"550",align:"left"}}),i("Desktop-Text",{attrs:{text:"This function simply does the job of splitting a text into tokens and counting the frequency. It is possible to adjust some parameters on this function but I left it in default mode."}}),i("Desktop-Text",{attrs:{text:"TfidTransformer",size:"15px",weight:"550",align:"left"}}),i("Desktop-Text",{attrs:{text:"This sklearn function called TfidfTransformer applies the frequency weighting to our machine learning model. Without this process of weighting tokens, less frequent words would vanish in the training process later on. To sum up: the TfidfTransformer assigns less value to more frequent words and allocates more value to less frequent but perhaps more meaningful words."}}),i("Desktop-Text",{attrs:{text:"Training the Model",size:"18px",weight:"550",align:"left"}}),i("Desktop-Text",{attrs:{text:"For training my machine learning model I used a sklearn pipeline with a SGDClassifier. This pipeline object will apply every step of the BoW model to a given tweet."}}),i("Desktop-Text",{attrs:{text:"Before training the model, all the given data had to be split into a training and test set."}}),i("Desktop-Code",{attrs:{content:"   from sklearn.feature_extraction.text import TfidfVectorizer\n        from sklearn.pipeline import Pipeline\n        from sklearn.feature_extraction.text import CountVectorizer\n        from sklearn.feature_extraction.text import TfidfTransformer\n        from sklearn.linear_model import SGDClassifier\n        from sklearn.model_selection import train_test_split\n\n        x_train,x_test,y_train,y_test=train_test_split(train_upsampled['Text'],\n        train_upsampled['Label'],test_size=0.2)\n\n        pipeline=Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer())\n        ,('nb', SGDClassifier()),])"}}),i("Desktop-Text",{attrs:{text:"All it needs is to fit the training data into the pipeline and obtain a model. In the end, a prediction about the test data and the F1 score can be received."}}),i("Desktop-Code",{attrs:{content:"   from sklearn.metrics import f1_score\n\n        model=pipeline.fit(x_train,y_train)\n        y_predict=model.predict(x_test)\n\n        print(f1_score(y_test, y_predict))"}}),i("Desktop-Text",{attrs:{text:"This model achieved an F1 score of > 0.95 on the given test data and 0.90 on the final validation data. I was really surprised at how successful this rather basic approach was. I think this is a good foundation to get started with natural language processing but also has plenty of chances to improve."}}),i("Desktop-Text",{attrs:{text:"Check my GitHub for the full code!"}}),i("div",{staticClass:"line"},[i("b-button",{staticClass:"mb-2",attrs:{variant:"transparent",onclick:"window.open('https://github.com/JanFiedler11/AntiSem2020')"}},[i("b-icon",{attrs:{icon:"github",id:"github"}})],1),i("hr")],1),i("Desktop-Text",{attrs:{text:"Thank you for coming by 🙏",align:e.center}}),i("Desktop-Footer")],1),i("div",{attrs:{id:"mobile-body"}},[i("MobileEntry",{attrs:{title:"Identifying Antisemitic Tweets with Natural Language Processing in Python",subtitle:"Let me show you a basic approach to classify text with machine learning, which won a competition at the Indiana University. This post is for everybody, who would like to get started with natural language processing (NLP) in Python.",author_date:"Jan Fiedler ♥ Aug 18, 2020",picture:e.certificate}}),i("Mobile-Text",{attrs:{text:"Some weeks a good friend of mine, with a background in humanities and antisemitic studies, asked me if I would like to take part in an event at the Indiana University. The event was divided into a Datathon and Hackathon, a virtual workshop and competition with the goal to recognize antisemitism online and use programming to take care of this task automatically."}}),i("Mobile-Text",{attrs:{text:"You can read about the event in detail",linktext:"HERE!",link:"https://news.iu.edu/stories/2020/07/iub/24-antisemitism-workshop-twitter-competition-hackathon-datathon.html#"}}),i("Mobile-Text",{attrs:{text:"The use of social media in our modern society is huge and getting bigger by the day. With the increasing number of users, there is also a portion of people growing, who use these platforms as an outlet for homophobia, sexism, racism as well as antisemitism. Those hate speeches evolved from little internet trolls to a real pain to the digital society we are living in. The event aimed to fight against this particular threat and I was more than happy to contribute!"}}),i("Mobile-Text",{attrs:{text:"The Datathon was about manually annotating random tweets with keywords like „Jews“ or „Israel“ in it. For this task, a well-founded background in antisemitic studies was needed. The goal of the Hackathon, on the other hand, was to classify tweets programmatically as either antisemitic (1) or non-antisemitic (0). For the hackathon, a bunch of labeled data was given in a file. Because I was the only one with programming skills in the team, I was happy to think about a solution for the hackathon, even though I had no experience with NLP at all"}}),i("Mobile-Text",{attrs:{text:"4 weeks later",size:"60px",weight:"550",align:"left"}}),e._m(2),i("Mobile-Text",{attrs:{text:'"The first prize of $500 went to Jan Fiedler, Sydney Grad, Sophie Mariassy and Victor Tschiskale, students from Canada and Germany."',size:"50px",weight:"100",align:"center"}}),e._m(3),i("Mobile-Text",{attrs:{text:"We actually won!"}}),i("Mobile-Text",{attrs:{text:"The rest of my team annotated a crazy amount of tweets properly, which won us the datathon. For the hackathon, we also took first place because of my machine learning model, which achieved an F1 score of 0.90 on the final validation data."}}),i("Mobile-Text",{attrs:{text:"A basic NLP approach",size:"60px",weight:"550",align:"left"}}),i("Mobile-Text",{attrs:{text:"In the following article, I want to reveal you a really basic approach for classifying text in Python. This approach is based on an article from Rebecca Vickery on",linktext:"medium.",link:"https://medium.com/vickdata/detecting-hate-speech-in-tweets-natural-language-processing-in-python-for-beginners-4e591952223"}}),i("Mobile-Text",{attrs:{text:"Thank you so much for sharing!"}}),i("Mobile-Text",{attrs:{text:"The Data",size:"50px",weight:"550",align:"left"}}),i("Mobile-Text",{attrs:{text:"As I said, there was a data set given in a JSON file, consisting of labeled tweets either as antisemitic (1) or non-antisemitic (0). I converted the given JSON into a pandas data frame to keep the data science manner 🙂"}}),i("MobileTable",{attrs:{items:e.table0,caption:"a part of the given data set"}}),i("Mobile-Text",{attrs:{text:"Cleaning the Data",size:"50px",weight:"550",align:"left"}}),i("Mobile-Text",{attrs:{text:"In order to make any machine algorithm work well, I had to pre-process the given text data. As you can see, tweets contain characters like hashtags or emojis, which won’t be meaningful to a machine learning algorithm."}}),i("Mobile-Text",{attrs:{text:"I am using the re library in Python for removing these characters."}}),i("Mobile-Code",{attrs:{content:' import re\n\n      def f_clean_data(df,field):\n          df[field]=df[field].str.lower()\n          df[field] = df[field].apply(lambda elem: \n          re.sub(r"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?","", elem))\n          return df'}}),i("Mobile-Text",{attrs:{text:"This function also converts every word in lower case, which is nice because the following algorithm will count the frequency of words. Without this processing, a lower and upper version of the same word would count differently, even if the meaning is the same.\nLet’s have a look at the cleaned data."}}),i("MobileTable",{attrs:{items:e.table1,caption:"a part of the given data set - cleaned"}}),i("Mobile-Text",{attrs:{text:"This is looking a lot cleaner. After some research, I thought another important step of cleaning my tweets is needed: removing stop words and lemmatization. Stop words are the most common and basic words in a language like „to“, „the“ or „and“. Those words had to be removed because they can’t give a hint about the intention of a tweet. Lemmatization is a linguistic process of affiliating a word to its very basic form (lemma). For example „runs“, „ran“ and „running“ are forms of the same lemma: „run“. Like in the lowercase processing, this is really important to identify equal words even if they are in different forms."}}),i("Mobile-Text",{attrs:{text:"I implemented this by using spacy, a really strong library for NLP. I am basically splitting up my tweet as a text in separate words (tokens). If the token is a stop word, I don’t want to append it to my cleaned text. If it is not a stop word, I want to apply the lemmatization and append it to my cleaned text."}}),i("Mobile-Code",{attrs:{content:' import spacy\n\n      nlp=spacy.load("en_core_web_sm")\n\n      def remove_stop_apply_lemma_for_string(text):\n          cleaned_text=""\n          tokens=nlp(text)\n          for token in tokens:\n              if not token.is_stop:\n                  cleaned_text=cleaned_text+" "+token.lemma_\n    \n          return cleaned_text'}}),i("Mobile-Text",{attrs:{text:"At this point in pre-processing the tweets, it is getting harder to understand the text as a human being. On the other hand, this will improve the performance of our algorithm in the end."}}),i("MobileTable",{attrs:{items:e.table2,caption:"a part of the given data set – applied lemmatization and removed stop words"}}),i("Mobile-Text",{attrs:{text:"Balancing the Classes",size:"55px",weight:"550",align:"left"}}),i("Mobile-Text",{attrs:{text:"After having the data cleaned I realized, that the number of non-antisemitic tweets predominated the antisemitic tweets. If the machine learning model is only being fed with tweets, which are labeled as 0, it is more likely, that it will predict new tweets to 0 in the end.\nHaving the classes balanced is an important requirement to proceed in this stage."}}),i("Mobile-Text",{attrs:{text:"It is one approach, to either upsample or downsample the minority/majority of a class. At this point, it was really about trying which method scores better results. I went for upsampling the minority, where samples of the minority are being used multiple times until the class is the same size as the majority. For this implementation, I used the functions of the sklearn library."}}),i("Mobile-Code",{attrs:{content:' from sklearn.utils import resample\n      import pandas as pd\n\n      #they are like 1200 more antisemitic tweets than not antisemitic.\n      #Thats why we are upsampling the minority.\n      train_majority=clean_data[clean_data.Label=="0"]\n      train_minority=clean_data[clean_data.Label=="1"]\n    \n      train_minority_upsampled=resample(train_minority,replace=True,\n      n_samples=len(train_majority),random_state=123)\n\n      train_upsampled=pd.concat([train_minority_upsampled,train_majority])'}}),i("Mobile-Text",{attrs:{text:"The Algorithm",size:"55px",weight:"550",align:"left"}}),i("Mobile-Text",{attrs:{text:"After having our whole data-set prepared, let’s have a look at the chosen algorithm. A common approach to detect patterns in text is the use of the Bag of Words (BoW) model. A BoW model counts the frequency of single words and assigns a weight proportional to this frequency. I built this model with the help of the functions of the sklearn library."}}),i("Mobile-Text",{attrs:{text:"CountVectoriser",size:"45px",weight:"550",align:"left"}}),i("Mobile-Text",{attrs:{text:"This function simply does the job of splitting a text into tokens and counting the frequency. It is possible to adjust some parameters on this function but I left it in default mode."}}),i("Mobile-Text",{attrs:{text:"TfidTransformer",size:"45px",weight:"550",align:"left"}}),i("Mobile-Text",{attrs:{text:"This sklearn function called TfidfTransformer applies the frequency weighting to our machine learning model. Without this process of weighting tokens, less frequent words would vanish in the training process later on. To sum up: the TfidfTransformer assigns less value to more frequent words and allocates more value to less frequent but perhaps more meaningful words."}}),i("Mobile-Text",{attrs:{text:"Training the Model",size:"55px",weight:"550",align:"left"}}),i("Mobile-Text",{attrs:{text:"For training my machine learning model I used a sklearn pipeline with a SGDClassifier. This pipeline object will apply every step of the BoW model to a given tweet."}}),i("Mobile-Text",{attrs:{text:"Before training the model, all the given data had to be split into a training and test set."}}),i("Mobile-Code",{attrs:{content:"   from sklearn.feature_extraction.text import TfidfVectorizer\n        from sklearn.pipeline import Pipeline\n        from sklearn.feature_extraction.text import CountVectorizer\n        from sklearn.feature_extraction.text import TfidfTransformer\n        from sklearn.linear_model import SGDClassifier\n        from sklearn.model_selection import train_test_split\n\n        x_train,x_test,y_train,y_test=train_test_split(train_upsampled['Text'],\n        train_upsampled['Label'],test_size=0.2)\n\n        pipeline=Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer())\n        ,('nb', SGDClassifier()),])"}}),i("Mobile-Text",{attrs:{text:"All it needs is to fit the training data into the pipeline and obtain a model. In the end, a prediction about the test data and the F1 score can be received."}}),i("Mobile-Code",{attrs:{content:"   from sklearn.metrics import f1_score\n\n        model=pipeline.fit(x_train,y_train)\n        y_predict=model.predict(x_test)\n\n        print(f1_score(y_test, y_predict))"}}),i("Mobile-Text",{attrs:{text:"This model achieved an F1 score of > 0.95 on the given test data and 0.90 on the final validation data. I was really surprised at how successful this rather basic approach was. I think this is a good foundation to get started with natural language processing but also has plenty of chances to improve."}}),i("Mobile-Text",{attrs:{text:"Check my GitHub for the full code!"}}),i("div",{staticClass:"mobileline"},[i("b-button",{staticClass:"mb-2",attrs:{variant:"transparent",onclick:"window.open('https://github.com/JanFiedler11/AntiSem2020')"}},[i("b-icon",{attrs:{icon:"github",id:"github"}})],1),i("hr")],1),i("Mobile-Text",{attrs:{text:"Thank you for coming by 🙏",align:e.center}}),i("Mobile-Footer")],1)])},H=[function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"line"},[i("hr")])},function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"line"},[i("hr")])},function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"mobileline"},[i("hr")])},function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"mobileline"},[i("hr")])}],q=function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("div",{staticClass:"header"},[a("Drawer",{attrs:{align:"left",closeable:!0},on:{close:e.toggle}},[e.open?a("div",{staticClass:"about-card"},[a("div",{staticClass:"about-entry"},[a("p",{attrs:{id:"about-me"}},[e._v(" About me")]),a("h3",{attrs:{id:"myname"}},[e._v("Jan Fiedler")]),a("img",{attrs:{id:"picture",src:i("44da"),width:"400px",height:"400px"}})]),a("div",{staticClass:"about-text"},[a("p",[e._v(" I am a student from Berlin with an affinity for computer technology and a bachelor's degree in electrical engineering. In 2021, I will finish my master's study in Computer Engineering. The process of developing hard- and software has been and still is an extremely fulfilling joy for me. I am pretty much interested in the whole stack, from embedded to web, and everything in between. This is why I tend to do some side projects from time to time, which I want to share with everybody. Thanks for coming by :) ")])])]):e._e()]),a("div",{staticClass:"webname"},[a("h1",{attrs:{id:"Home"},on:{click:function(t){return e.$router.push("/")}}},[e._v("Home")]),a("div",{staticClass:"icon-list"},[a("b-button",{staticClass:"mb-2",attrs:{variant:"transparent"},on:{click:function(t){return e.toggle()}}},[a("b-icon",{staticClass:"icons",attrs:{icon:"person-fill",id:"person"}})],1),a("b-button",{staticClass:"mb-2",attrs:{variant:"transparent",onclick:"javascript: window.location.href='mailto:jan.fiedler.b@gmail.com';"}},[a("b-icon",{staticClass:"icons",attrs:{icon:"envelope-fill",id:"mail"}})],1),a("b-button",{staticClass:"mb-2",attrs:{variant:"transparent",onclick:"window.open('https://www.linkedin.com/in/jan-fiedler-285856186')"}},[a("b-icon",{staticClass:"icons",attrs:{icon:"linkedin",id:"linkedin"}})],1)],1)])],1)},$=[],J={name:"header",data:function(){return{open:!1}},components:{Drawer:d.a},methods:{toggle:function(){this.open=!this.open}}},B=J,W=(i("4d41"),Object(p["a"])(B,q,$,!1,null,"1bd142e0",null)),R=W.exports,G=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"entry"},[i("h1",{attrs:{id:"title"}},[e._v(e._s(e.title))]),i("h5",{attrs:{id:"subtitle"}},[e._v(" "+e._s(e.subtitle))]),i("hr",{attrs:{id:"line"}}),i("h5",{attrs:{id:"author_date"}},[e._v(" "+e._s(e.author_date))]),i("img",{attrs:{src:e.picture,id:"picture",width:"750px",height:"auto"}})])},V=[],U={props:{title:{type:String,default:"New Title"},picture:{type:String,default:i("0af9")},author_date:{type:String,default:"Jan Fiedler ♥ some date"},subtitle:{type:String,default:"Title of the article"}}},Y=U,Z=(i("9079"),Object(p["a"])(Y,G,V,!1,null,"2b3f7218",null)),K=Z.exports,Q=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"text"},[i("p",{style:{fontSize:e.size,fontWeight:e.weight,textAlign:e.align}},[e._v(e._s(e.text)+" "),i("a",{attrs:{target:"_blank",rel:"noopener noreferrer",href:e.link}},[e._v(e._s(e.linktext))])])])},X=[],ee={props:{text:{type:String,default:"text text text"},size:{type:String,default:"18px"},weight:{type:String,default:"350"},align:{type:String,default:"left"},linktext:{type:String,default:""},link:{type:String,default:"https://news.iu.edu/stories/2020/07/iub/24-antisemitism-workshop-twitter-competition-hackathon-datathon.html#"}}},te=ee,ie=(i("90af"),Object(p["a"])(te,Q,X,!1,null,"af5cfff4",null)),ae=ie.exports,ne=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"code"},[i("pre",{directives:[{name:"highlightjs",rawName:"v-highlightjs"}]},[i("code",{staticClass:"python"},[e._v("\n     "+e._s(e.content)+"\n      ")])])])},oe=[],se={props:{content:{type:String,default:"text text text"}}},re=se,le=(i("d79b"),Object(p["a"])(re,ne,oe,!1,null,"02b68504",null)),ce=le.exports,de=i("1d61"),he=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"table"},[i("b-table",{attrs:{id:"maintable",hover:"",fields:e.fields,items:e.items}}),i("div",{staticClass:"Ccaption"},[i("p",[e._v(e._s(e.caption)+" ")])])],1)},ue=[],pe={props:{items:[],caption:{type:String,default:"text text text"}},data:function(){return{fields:[{key:"Nr",sortable:!0,variant:"light"},{key:"Label",sortable:!0,variant:"light"},{key:"Text",label:"Text",sortable:!1,variant:"light"}]}}},me=pe,fe=(i("c91f"),Object(p["a"])(me,he,ue,!1,null,"65d897fa",null)),ge=fe.exports,we=function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("div",{staticClass:"header"},[a("Drawer",{attrs:{align:"left",closeable:!0},on:{close:e.toggle}},[e.open?a("div",{staticClass:"about-card"},[a("div",{staticClass:"about-entry"},[a("p",{attrs:{id:"about-me"}},[e._v(" About me")]),a("h3",{attrs:{id:"myname"}},[e._v("Jan Fiedler")]),a("img",{attrs:{id:"picture",src:i("44da"),width:"400px",height:"400px"}})]),a("div",{staticClass:"about-text"},[a("p",[e._v(" I am a student from Berlin with an affinity for computer technology and a bachelor's degree in electrical engineering. In 2021, I will finish my master's study in Computer Engineering. The process of developing hard- and software has been and still is an extremely fulfilling joy for me. I am pretty much interested in the whole stack, from embedded to web, and everything in between. This is why I tend to do some side projects from time to time, which I want to share with everybody. Thanks for coming by :) ")])])]):e._e()]),a("div",{staticClass:"webname"},[a("h1",{attrs:{id:"website-name"},on:{click:function(t){return e.$router.push("/")}}},[e._v("Jan-Fiedler")]),a("h3",[e._v("IoT Enthusiast, maker and electrical engineer")]),a("div",{staticClass:"icon-list"},[a("b-button",{staticClass:"mb-2",attrs:{variant:"transparent"},on:{click:function(t){return e.toggle()}}},[a("b-icon",{staticClass:"icons",attrs:{icon:"person-fill",id:"person"}})],1),a("b-button",{staticClass:"mb-2",attrs:{variant:"transparent",onclick:"javascript: window.location.href='mailto:jan.fiedler.b@gmail.com';"}},[a("b-icon",{staticClass:"icons",attrs:{icon:"envelope-fill",id:"mail"}})],1),a("b-button",{staticClass:"mb-2",attrs:{size:"lg",variant:"transparent",onclick:"window.open('https://www.linkedin.com/in/jan-fiedler-285856186')"}},[a("b-icon",{staticClass:"icons",attrs:{icon:"linkedin",id:"linkedin"}})],1)],1)])],1)},be=[],ye={name:"header",data:function(){return{open:!1}},components:{Drawer:d.a},methods:{toggle:function(){this.open=!this.open}}},xe=ye,ve=(i("c2fc"),Object(p["a"])(xe,we,be,!1,null,"069e6c8b",null)),ke=ve.exports,Te=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"entry"},[i("h1",{attrs:{id:"title"}},[e._v(e._s(e.title))]),i("h5",{attrs:{id:"subtitle"}},[e._v(" "+e._s(e.subtitle))]),i("hr",{attrs:{id:"line"}}),i("h5",{attrs:{id:"author_date"}},[e._v(" "+e._s(e.author_date))]),i("img",{attrs:{src:e.picture,id:"picture"}})])},_e=[],Ie={props:{title:{type:String,default:"New Title"},picture:{type:String,default:i("0af9")},author_date:{type:String,default:"Jan Fiedler ♥ some date"},subtitle:{type:String,default:"Title of the article"}}},Ce=Ie,Me=(i("fc6e"),Object(p["a"])(Ce,Te,_e,!1,null,"501305d9",null)),De=Me.exports,je=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"text"},[i("p",{style:{fontSize:e.size,fontWeight:e.weight,textAlign:e.align}},[e._v(e._s(e.text)+" "),i("a",{style:{fontSize:e.size,fontWeight:e.weight},attrs:{target:"_blank",rel:"noopener noreferrer",href:e.link}},[e._v(e._s(e.linktext))])])])},ze=[],Ae={props:{text:{type:String,default:"text text text"},size:{type:String,default:"45px"},weight:{type:String,default:"350"},align:{type:String,default:"left"},linktext:{type:String,default:""},link:{type:String,default:"window.open('https://www.linkedin.com/in/jan-fiedler-285856186')"}}},Se=Ae,Le=(i("60ef"),Object(p["a"])(Se,je,ze,!1,null,"22287777",null)),Pe=Le.exports,Ee=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"code"},[i("pre",{directives:[{name:"highlightjs",rawName:"v-highlightjs"}]},[i("code",{staticClass:"python"},[e._v("\n     "+e._s(e.content)+"\n      ")])])])},Ne=[],Fe={props:{content:{type:String,default:"text text text"}}},Oe=Fe,He=(i("f633"),Object(p["a"])(Oe,Ee,Ne,!1,null,"6da69e3a",null)),qe=He.exports,$e=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"table"},[i("b-table",{attrs:{id:"maintable",hover:"",fields:e.fields,items:e.items}}),i("div",{staticClass:"Ccaption"},[i("p",[e._v(e._s(e.caption)+" ")])])],1)},Je=[],Be={props:{items:[],caption:{type:String,default:"text text text"}},data:function(){return{fields:[{key:"Nr",sortable:!0,variant:"light"},{key:"Label",sortable:!0,variant:"light"},{key:"Text",label:"Text",sortable:!1,variant:"light"}]}}},We=Be,Re=(i("0942"),Object(p["a"])(We,$e,Je,!1,null,"a5aa77f8",null)),Ge=Re.exports,Ve=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"footer"},[i("h3",{on:{click:function(t){return e.$router.push("/")}}},[e._v(" jan-fiedler.net © 2021 | Latest Posts ")])])},Ue=[],Ye={created:function(){window.scrollTo(0,0)}},Ze=Ye,Ke=(i("1512"),Object(p["a"])(Ze,Ve,Ue,!1,null,"2f6a0626",null)),Qe=Ke.exports,Xe={name:"Home",components:{DesktopHeader:R,MobileHeader:ke,DesktopEntry:K,DesktopText:ae,DesktopCode:ce,DesktopFooter:de["default"],MobileEntry:De,MobileText:Pe,MobileCode:qe,MobileTable:Ge,MobileFooter:Qe,DesktopTable:ge},data:function(){return{certificate:i("c434"),table0:[{Nr:0,Label:0,Text:"RT @purplechrain: so members of the GOP have, as predicted, officially started combining “liberal & leftist Jews aren’t real Jews & thus it…"},{Nr:1,Label:0,Text:"„RT @Laurent_Weppe: @the_moviebob SAME White petit bourgeois start openly saying stuff like „“beating to death Niggers and Kikes make my dick…"},{Nr:2,Label:1,Text:"„🗼 #unpopularopinion #MAGA The crisis currently plaguing kikes conceivably will be feral cats 🙂 Mad . 🙅 🐔 ↔ 🚶 💜 🌜 🆙 👪 🚠 🚙 🐚 🈶"},{Nr:3,Label:1,Text:"„@Michael__Baskin @mattduss Again, you are changing the subject. Are you a zionazi? hmm?Why does international law apply to others, but not Israel? This was the original point.This massive zionist influence and control over our politics needs to go, and dual loyalists should be given the death penalty.“"},{Nr:4,Label:1,Text:"„True, but that won’t stop the ZioNazi run #NATO & its corrupt, arrogant #Ottoman Nazi hireling from attacking Syria while useless, spineless #Putin just sits and watches..#CapeTown #SouthAFrica“"}],table1:[{Nr:0,Label:0,Text:"so members of the gop have as predicted officially started combining liberal amp leftist jews arent real jews amp thus it"},{Nr:1,Label:0,Text:"weppe moviebob same white petit bourgeois start openly saying stuff like beating to death niggers and kikes make my dick"},{Nr:2,Label:1,Text:"unpopularopinion maga the crisis currently plaguing kikes conceivably will be feral cats mad"},{Nr:3,Label:1,Text:"baskin again you are changing the subject are you a zionazi hmmwhy does international law apply to others but not israel this was the original pointthis massive zionist influence and control over our politics needs to go and dual loyalists should be given the death penalty"},{Nr:4,Label:1,Text:"true but that wont stop the zionazi run nato amp its corrupt arrogant ottoman nazi hireling from attacking syria while useless spineless putin just sits and watchescapetown southafrica"}],table2:[{Nr:0,Label:0,Text:"member gop predict officially start combine liberal amp leftist jews not real jews amp"},{Nr:1,Label:0,Text:"\tweppe moviebob white petit bourgeois start openly say stuff like beat death nigger kike dick"},{Nr:2,Label:1,Text:"unpopularopinion maga crisis currently plaguing kike conceivably feral cat mad"},{Nr:3,Label:1,Text:"baskin change subject zionazi hmmwhy international law apply israel original pointthis massive zionist influence control politic need dual loyalist give death penalty"},{Nr:4,Label:1,Text:"true will not stop zionazi run nato amp corrupt arrogant ottoman nazi hirele attack syria useless spineless putin sit watchescapetown southafrica"}]}},methods:{go_to:function(e){this.$router.push({name:e})}}},et=Xe,tt=(i("13c2"),Object(p["a"])(et,O,H,!1,null,"abe3c768",null)),it=tt.exports,at=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"home"},[i("div",{staticClass:"my_header"},[i("DesktopHeader",{attrs:{id:"DesktopHeader"}}),i("MobileHeader",{attrs:{id:"MobileHeader"}})],1),i("div",{attrs:{id:"desktop-body"}},[i("DesktopEntry",{attrs:{title:"Audio Recognition with Embedded Machine Learning",subtitle:"How do Harry Potter, TinyML and an Arduino match each other, you may wonder? \n    Follow along and see how to become a wizard using embedded machine learning.",author_date:"Jan Fiedler ♥ Aug 02, 2020"}}),i("Desktop-Text",{attrs:{text:"Recently I got aware of something called tiny machine learning or TinyML. \n    TinyML is basically the latest technology for embedded systems, where deep learning and tiny devices are combined to create something very potential. \n    Traditional machine learning often runs on big powered hardware somewhere in the cloud and therefore requires a good amount of resources."}}),i("Desktop-Text",{attrs:{text:"With TinyML it is now possible to run machine learning models on the edge with devices like the Arduino nano 33 ble, which fits literally everywhere and only consumes about 20 mA."}}),i("Desktop-Picture",{attrs:{caption:"The Arduino Nano 33 BLE has an integrated 3 axis acceleration sensor, a microphone as well as an Bluetooth interface",width:"300px"}}),i("Desktop-Text",{attrs:{text:'The most common application of this technology is the recognition of wake words like Hey "Siri" or "Alexa" by known smart devices. \n    If those devices are in standby mode, a low powered chip is constantly waiting for you to say the wake word to power up the main CPU of the device.'}}),i("Desktop-Text",{attrs:{text:"In December 2019, Peter Waren and Daniel Situnayake made this public by releasing a book, which explains machine learning with TensorFlow Lite on Arduino and Ultra-Low-Power Micro-Controllers. Since then, things got even easier with the launch of Edge Impulse: TinyML as a service to enable machine learning for all developers. It provides the full TinyML Pipeline, starting by collecting data, building a model and deploying it to the device. As a result, the implementation of motion- and sound recognition or finding anomalies in sensor data became more accessible"}}),i("Desktop-Text",{attrs:{text:"So I decided to build a voice recognition model with edge impulse!",size:"25px",weight:"650",align:"center"}}),i("DesktopPictureSideText",{attrs:{picture:e.lumos,caption:"Because I am quite a big fan of Harry Potter, I thought it would be fun to build my own magic wand. If you are not into Harry Potter, let me tell you, that „Lumos“ is the spell for creating light. On the other hand „Nox“ makes the light disappear.",width:"250px"}}),i("Desktop-Text",{attrs:{text:"Data acquisition",size:"18px",weight:"550",align:"left"}}),i("Desktop-Text",{attrs:{text:"To get started with every machine learning project, you got to have some data in-store to train your model later on. Because I could not find datasets of people saying „Lumos“ or „Nox“ online, I had to sample the data myself. Thanks to Edge Impulse, this was not really a problem. After installing the Edge Impulse firmware on my Arduino and some further installations on my desktop PC I was able to record data and save it directly to my Edge Impulse project."}}),i("Desktop-Picture",{attrs:{caption:"Data acquisition in Edge Impulse",width:"800px",picture:e.data_acq}}),i("Desktop-Text",{attrs:{text:"So I took some time and recorded myself 12 minutes of data, which can be divided into 3 labels. Because I want my model to recognize me saying a spell name, I recorded myself ~4 minutes of saying „Lumos“ as well as“Nox“. Because the model also needs to recognize, what silence or noise looks like, I had to record ~4 min of noise as well."}}),i("Desktop-Text",{attrs:{text:"Building the model",size:"18px",weight:"550",align:"left"}}),i("Desktop-Text",{attrs:{text:"After collecting a sufficient amount of audio data, it was time to build our machine learning model. You can do this by adding pre-defined blocks to your „impulse-pipeline“:"}}),i("Desktop-Picture",{attrs:{caption:"Impulse Design",width:"1000px",picture:e.impulse}}),i("Desktop-Text",{attrs:{text:"At first, I had to configure my time-series data, which defines the window size and the window increase. The window size is simply a frame, where your recorded audio data is organized in. This setting also defines the time, the microphone of the Arduino is recording after the deployment. The window increase is an offset, which splits you recorded audio into even more data. The lower the window increase, the more data you are going to receive for training. 200 milliseconds worked pretty well for me."}}),i("Desktop-Text",{attrs:{text:"After cutting the data in parts, these window sized samples are going to be processed by an MFCC block. This is a well known processing for generating features from audio using Mel Frequency Cepstral Coefficients. The following picture shows the output of a recorded sample:"}}),i("Desktop-Picture",{attrs:{caption:"DSP Result of noise",width:"800px",picture:e.mfcc}}),i("Desktop-Text",{attrs:{text:"This MFCC processing converts the raw audio signal in a frequency bucket matrix, where features can be extracted for learning our model."}}),i("Desktop-Text",{attrs:{text:"Edge Impulse offers a pretty cool view to observe all processed features of your recorded data. Mine looked like that:"}}),i("Desktop-Picture",{attrs:{caption:"Feature explorer view - lumos, nox and noise",width:"800px",picture:e.features}}),i("Desktop-Text",{attrs:{text:"One can see, that the processed features of each label are more or less separated, which is quite promising for our model."}}),i("Desktop-Text",{attrs:{text:"At last, I am adding a Nearest Neighbour classifier for my learning block in the „impulse pipeline“ by changing some training parameters, I am pretty much done building my machine learning model. It is time to let the model train!"}}),i("Desktop-Text",{attrs:{text:"Training the model",size:"18px",weight:"550",align:"left"}}),i("Desktop-Picture",{attrs:{caption:"Training performance",width:"1000px",picture:e.result}}),i("Desktop-Text",{attrs:{text:"Sweet! Those results are looking pretty good. I was aware of the effect of overfitting my data but some live classification assured me, that the model is working not too shabby. In this article, I am not going over the process of live classification and retraining your model. I just want to mention, that this also works quite well."}}),i("Desktop-Text",{attrs:{text:"Deployment",size:"18px",weight:"550",align:"left"}}),i("Desktop-Text",{attrs:{text:"There are several possibilities to deploy your generated model to your device. One of them is creating a Arduino library in Edge Impulse and importing it in the Arduino IDE. This library comes with examples for testing your model, which makes it extremely easy to adjust the code for your specific use case."}}),i("Desktop-Text",{attrs:{text:"Result",size:"18px",weight:"550",align:"left"}}),i("Desktop-Text",{attrs:{text:"Like I said in the beginning, I wanted to light up something, when saying „Lumos“ or shut the light, when saying „Nox“. I also wanted the microphone to only record, while a button is pressed. This is why I added some code and did some soldering on my Arduino. I really wanted this project to be fully embedded, so a battery block is attached at the back of my „wand“. So here it is:"}}),i("Desktop-Picture",{attrs:{caption:"poor mans wand",width:"400px",picture:e.wand}}),i("Desktop-Text",{attrs:{text:"Okay, it may not be as pretty and powerful as Dumbledores Elderwand, but it is quite functional. 🙂"}}),i("Desktop-Text",{attrs:{text:"Let me show you:"}}),i("iframe",{attrs:{id:"youtube",width:"700",height:"400",src:"https://www.youtube.com/embed/7hcYYn1x_Hs",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""}}),i("Desktop-Text",{attrs:{text:"I am sure, they are some more easy ways to detect words or speech in general, but this project was just about trying out TinyML. Just think about how easy and cheap you could realize predictive maintenance with these tools. I am really excited, what people are going to build with this technology."}}),e._m(0),i("Desktop-Text",{attrs:{text:"Thank you for coming by 🙏",align:e.center}}),i("Desktop-Footer")],1),i("div",{attrs:{id:"mobile-body"}},[i("MobileEntry",{attrs:{title:"Audio Recognition with Embedded Machine Learning",subtitle:"How do Harry Potter, TinyML and an Arduino match each other, you may wonder? \n    Follow along and see how to become a wizard using embedded machine learning.",author_date:"Jan Fiedler ♥ Aug 02, 2020"}}),i("MobileText",{attrs:{text:"Recently I got aware of something called tiny machine learning or TinyML. \n    TinyML is basically the latest technology for embedded systems, where deep learning and tiny devices are combined to create something very potential. \n    Traditional machine learning often runs on big powered hardware somewhere in the cloud and therefore requires a good amount of resources."}}),i("Mobile-Text",{attrs:{text:"With TinyML it is now possible to run machine learning models on the edge with devices like the Arduino nano 33 ble, which fits literally everywhere and only consumes about 20 mA."}}),i("Mobile-Picture",{attrs:{caption:"The Arduino Nano 33 BLE has an integrated 3 axis acceleration sensor, a microphone as well as an Bluetooth interface",width:"700px"}}),i("Mobile-Text",{attrs:{text:'The most common application of this technology is the recognition of wake words like Hey "Siri" or "Alexa" by known smart devices. \n    If those devices are in standby mode, a low powered chip is constantly waiting for you to say the wake word to power up the main CPU of the device.'}}),i("Mobile-Text",{attrs:{text:"In December 2019, Peter Waren and Daniel Situnayake made this public by releasing a book, which explains machine learning with TensorFlow Lite on Arduino and Ultra-Low-Power Micro-Controllers. Since then, things got even easier with the launch of Edge Impulse: TinyML as a service to enable machine learning for all developers. It provides the full TinyML Pipeline, starting by collecting data, building a model and deploying it to the device. As a result, the implementation of motion- and sound recognition or finding anomalies in sensor data became more accessible"}}),i("Mobile-Text",{attrs:{text:"So I decided to build a voice recognition model with edge impulse!",size:"60px",weight:"650",align:"center"}}),i("MobilePictureSideText",{attrs:{picture:e.lumos,caption:"Because I am quite a big fan of Harry Potter, I thought it would be fun to build my own magic wand. If you are not into Harry Potter, let me tell you, that „Lumos“ is the spell for creating light. On the other hand „Nox“ makes the light disappear.",width:"450px"}}),i("Mobile-Text",{attrs:{text:"Data acquisition",size:"55px",weight:"550",align:"left"}}),i("Mobile-Text",{attrs:{text:"To get started with every machine learning project, you got to have some data in-store to train your model later on. Because I could not find datasets of people saying „Lumos“ or „Nox“ online, I had to sample the data myself. Thanks to Edge Impulse, this was not really a problem. After installing the Edge Impulse firmware on my Arduino and some further installations on my Mobile PC I was able to record data and save it directly to my Edge Impulse project."}}),i("Mobile-Picture",{attrs:{caption:"Data acquisition in Edge Impulse",width:"100%",picture:e.data_acq}}),i("Mobile-Text",{attrs:{text:"So I took some time and recorded myself 12 minutes of data, which can be divided into 3 labels. Because I want my model to recognize me saying a spell name, I recorded myself ~4 minutes of saying „Lumos“ as well as“Nox“. Because the model also needs to recognize, what silence or noise looks like, I had to record ~4 min of noise as well."}}),i("Mobile-Text",{attrs:{text:"Building the model",size:"55px",weight:"550",align:"left"}}),i("Mobile-Text",{attrs:{text:"After collecting a sufficient amount of audio data, it was time to build our machine learning model. You can do this by adding pre-defined blocks to your „impulse-pipeline“:"}}),i("Mobile-Picture",{attrs:{caption:"Impulse Design",width:"100%",picture:e.impulse}}),i("Mobile-Text",{attrs:{text:"At first, I had to configure my time-series data, which defines the window size and the window increase. The window size is simply a frame, where your recorded audio data is organized in. This setting also defines the time, the microphone of the Arduino is recording after the deployment. The window increase is an offset, which splits you recorded audio into even more data. The lower the window increase, the more data you are going to receive for training. 200 milliseconds worked pretty well for me."}}),i("Mobile-Text",{attrs:{text:"After cutting the data in parts, these window sized samples are going to be processed by an MFCC block. This is a well known processing for generating features from audio using Mel Frequency Cepstral Coefficients. The following picture shows the output of a recorded sample:"}}),i("Mobile-Picture",{attrs:{caption:"DSP Result of noise",width:"100%",picture:e.mfcc}}),i("Mobile-Text",{attrs:{text:"This MFCC processing converts the raw audio signal in a frequency bucket matrix, where features can be extracted for learning our model."}}),i("Mobile-Text",{attrs:{text:"Edge Impulse offers a pretty cool view to observe all processed features of your recorded data. Mine looked like that:"}}),i("Mobile-Picture",{attrs:{caption:"Feature explorer view - lumos, nox and noise",width:"100%",picture:e.features}}),i("Mobile-Text",{attrs:{text:"One can see, that the processed features of each label are more or less separated, which is quite promising for our model."}}),i("Mobile-Text",{attrs:{text:"At last, I am adding a Nearest Neighbour classifier for my learning block in the „impulse pipeline“ by changing some training parameters, I am pretty much done building my machine learning model. It is time to let the model train!"}}),i("Mobile-Text",{attrs:{text:"Training the model",size:"55px",weight:"550",align:"left"}}),i("Mobile-Picture",{attrs:{caption:"Training performance",width:"100%",picture:e.result}}),i("Mobile-Text",{attrs:{text:"Sweet! Those results are looking pretty good. I was aware of the effect of overfitting my data but some live classification assured me, that the model is working not too shabby. In this article, I am not going over the process of live classification and retraining your model. I just want to mention, that this also works quite well."}}),i("Mobile-Text",{attrs:{text:"Deployment",size:"55px",weight:"550",align:"left"}}),i("Mobile-Text",{attrs:{text:"There are several possibilities to deploy your generated model to your device. One of them is creating a Arduino library in Edge Impulse and importing it in the Arduino IDE. This library comes with examples for testing your model, which makes it extremely easy to adjust the code for your specific use case."}}),i("Mobile-Text",{attrs:{text:"Result",size:"55px",weight:"550",align:"left"}}),i("Mobile-Text",{attrs:{text:"Like I said in the beginning, I wanted to light up something, when saying „Lumos“ or shut the light, when saying „Nox“. I also wanted the microphone to only record, while a button is pressed. This is why I added some code and did some soldering on my Arduino. I really wanted this project to be fully embedded, so a battery block is attached at the back of my „wand“. So here it is:"}}),i("Mobile-Picture",{attrs:{caption:"poor mans wand",width:"80%",picture:e.wand}}),i("Mobile-Text",{attrs:{text:"Okay, it may not be as pretty and powerful as Dumbledores Elderwand, but it is quite functional. 🙂"}}),i("Mobile-Text",{attrs:{text:"Let me show you:"}}),i("iframe",{attrs:{id:"youtube",width:"90%",height:"600",src:"https://www.youtube.com/embed/7hcYYn1x_Hs",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""}}),i("Mobile-Text",{attrs:{text:"I am sure, they are some more easy ways to detect words or speech in general, but this project was just about trying out TinyML. Just think about how easy and cheap you could realize predictive maintenance with these tools. I am really excited, what people are going to build with this technology."}}),e._m(1),i("Mobile-Text",{attrs:{text:"Thank you for coming by 🙏",align:"center"}}),i("Mobile-Footer")],1)])},nt=[function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"line"},[i("hr")])},function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"line"},[i("hr")])}],ot=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"Cpicture",attrs:{width:e.width}},[i("img",{attrs:{src:e.picture,id:"picture",width:e.width,height:"auto"}}),i("div",{staticClass:"Ccaption",style:{width:e.width}},[i("p",[e._v(e._s(e.caption)+" ")])])])},st=[],rt={props:{caption:{type:String,default:"text text text"},picture:{type:String,default:i("dfd1")},width:{type:String,default:"300px"}}},lt=rt,ct=(i("c4348"),Object(p["a"])(lt,ot,st,!1,null,"7ca12f52",null)),dt=ct.exports,ht=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"Cpicture",attrs:{width:e.width}},[i("img",{attrs:{src:e.picture,id:"picture",width:e.width,height:"auto"}}),i("div",{staticClass:"Ccaption",style:{width:e.width}},[i("p",[e._v(e._s(e.caption)+" ")])])])},ut=[],pt={props:{caption:{type:String,default:"text text text"},picture:{type:String,default:i("dfd1")},width:{type:String,default:"300px"}}},mt=pt,ft=(i("d998"),Object(p["a"])(mt,ht,ut,!1,null,"0f8985f5",null)),gt=ft.exports,wt=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"Cpicture",attrs:{width:e.width}},[i("img",{attrs:{src:e.picture,id:"picture",width:e.width,height:"auto"}}),i("div",{staticClass:"Ccaption",style:{width:e.width}},[i("p",[e._v(e._s(e.caption)+" ")])])])},bt=[],yt={props:{caption:{type:String,default:"text text text"},picture:{type:String,default:i("dfd1")},width:{type:String,default:"300px"}}},xt=yt,vt=(i("2efa"),Object(p["a"])(xt,wt,bt,!1,null,"1b994acc",null)),kt=vt.exports,Tt=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"Cpicture",attrs:{width:e.width}},[i("img",{attrs:{src:e.picture,id:"picture",width:e.width,height:"auto"}}),i("div",{staticClass:"Ccaption",style:{width:e.width}},[i("p",[e._v(e._s(e.caption)+" ")])])])},_t=[],It={props:{caption:{type:String,default:"text text text"},picture:{type:String,default:i("dfd1")},width:{type:String,default:"300px"}}},Ct=It,Mt=(i("8d94"),Object(p["a"])(Ct,Tt,_t,!1,null,"da5d0b1a",null)),Dt=Mt.exports,jt={name:"Home",components:{DesktopHeader:R,MobileHeader:ke,DesktopEntry:K,DesktopText:ae,DesktopPicture:dt,DesktopPictureSideText:gt,DesktopFooter:de["default"],MobileEntry:De,MobileText:Pe,MobilePicture:kt,MobilePictureSideText:Dt,MobileFooter:Qe},data:function(){return{lumos:i("53e5"),data_acq:i("5040"),impulse:i("2e4c"),mfcc:i("8025"),features:i("59fd"),result:i("265a"),wand:i("71ec")}},methods:{go_to:function(e){this.$router.push({name:e})}}},zt=jt,At=(i("b4d5"),Object(p["a"])(zt,at,nt,!1,null,"799def7d",null)),St=At.exports;a["default"].use(n["a"]);var Lt=[{path:"/",name:"Home",component:F},{path:"*",name:"Home",component:F},{path:"/nlp-identifying-antisemitic-tweets",name:"Nlp",component:it},{path:"/tinyml-audio-recognition",name:"TinyML",component:St}],Pt=new n["a"]({routes:Lt,mode:"history"}),Et=Pt,Nt=i("1e18"),Ft=i("b1e0"),Ot=(i("f9e3"),i("2dd8"),function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{attrs:{id:"app"}},[i("router-view")],1)}),Ht=[],qt=(i("034f"),{}),$t=Object(p["a"])(qt,Ot,Ht,!1,null,null,null),Jt=$t.exports,Bt=i("1487"),Wt=i.n(Bt);a["default"].directive("highlightjs",{deep:!0,bind:function(e,t){var i=e.querySelectorAll("code");i.forEach((function(e){t.value&&(e.textContent=t.value),Wt.a.highlightBlock(e)}))},componentUpdated:function(e,t){var i=e.querySelectorAll("code");i.forEach((function(e){t.value&&(e.textContent=t.value,Wt.a.highlightBlock(e))}))}}),a["default"].config.productionTip=!1,a["default"].use(Nt["a"]),a["default"].use(Ft["a"]),new a["default"]({router:Et,render:function(e){return e(Jt)}}).$mount("#app")},"59fd":function(e,t,i){e.exports=i.p+"img/features.5e7674bc.png"},"5ced":function(e,t,i){},"60ef":function(e,t,i){"use strict";i("48fa")},6753:function(e,t,i){},"6ac6":function(e,t,i){},"6d9c":function(e,t,i){},"71ec":function(e,t,i){e.exports=i.p+"img/wand.2827b5d4.jpeg"},"75f3":function(e,t,i){},8025:function(e,t,i){e.exports=i.p+"img/mfcc.7d3ee2cc.png"},"822e":function(e,t,i){"use strict";i("ce6c")},"85ec":function(e,t,i){},8878:function(e,t,i){},"8d94":function(e,t,i){"use strict";i("0b62")},9079:function(e,t,i){"use strict";i("3c5f")},"90af":function(e,t,i){"use strict";i("a704")},"94e4":function(e,t,i){},"953c":function(e,t,i){"use strict";i("3f0c")},a704:function(e,t,i){},b261:function(e,t,i){"use strict";i("412b")},b4d5:function(e,t,i){"use strict";i("6753")},b84c:function(e,t,i){},bb36:function(e,t,i){},c2ec:function(e,t,i){"use strict";i.d(t,"a",(function(){return a})),i.d(t,"b",(function(){return n}));var a=function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("div",{staticClass:"footer"},[i("h3",{on:{click:function(t){return e.$router.push("/")}}},[e._v(" jan-fiedler.net © 2021 | Latest Posts ")])])},n=[]},c2fc:function(e,t,i){"use strict";i("b84c")},c434:function(e,t,i){e.exports=i.p+"img/Certificate_Jan-Fiedler.2973e47a.jpg"},c4348:function(e,t,i){"use strict";i("75f3")},c91f:function(e,t,i){"use strict";i("8878")},cccb:function(e,t,i){"use strict";i("5ced")},cd9e:function(e,t,i){},ce6c:function(e,t,i){},d1e6:function(e,t,i){"use strict";var a=i("1009"),n=i.n(a);t["default"]=n.a},d79b:function(e,t,i){"use strict";i("4f9b")},d998:function(e,t,i){"use strict";i("f250")},dfd1:function(e,t,i){e.exports=i.p+"img/arduino_nano_ble33.8c7f9f9e.jpeg"},f250:function(e,t,i){},f633:function(e,t,i){"use strict";i("bb36")},fbe2:function(e,t,i){},fc6e:function(e,t,i){"use strict";i("4d40")},fd6d:function(e,t,i){"use strict";i("6d9c")}});
//# sourceMappingURL=app.ad477ff2.js.map